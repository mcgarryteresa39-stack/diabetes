{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load the CSV file \n",
    "df = pd.read_csv(\"diabetes.csv\") \n",
    "\n",
    "# Set the display setting so that oclumns are shown across the screen and not truncated\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 2000)\n",
    "\n",
    "# Review the features to see what they look like and to check distributions\n",
    "print(df.shape)\n",
    "print(df.head(10))\n",
    "print(df.describe().T)\n",
    "print(df.info)\n",
    "\n",
    " # Review the data types of each feature. All are floats! \n",
    "df.columns.to_list()\n",
    "print(\"The datatypes are:\\n\", df.dtypes)\n",
    "\n",
    "# Reviewing the unique values \n",
    "print(\"The number of unique values is:\\n\",df.nunique().sort_values())\n",
    "\n",
    "# Reviewing the level of null values\n",
    "print(\"The level of null values is:\\n\", df.isnull().sum())\n",
    "\n",
    "# show all of the columns in diabetes with associated unique values\n",
    "for column in df.columns:\n",
    "    print(f\"\\ncolumn: {column}\")\n",
    "    print(sorted(df[column].unique()))\n",
    "\n",
    "# Check for missing values. There are no missing or unusual values! This dataset is remarkably clean!\n",
    "df.isna().sum().sort_values(ascending=False)\n",
    "\n",
    "# EDA\n",
    "# We will look at the distrubutions of all variables (as all are floats)\n",
    "# Plot the data using bar charts \n",
    "for col in df.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "\n",
    "    # If the column is binary or categorical (few unique values)\n",
    "    if df[col].nunique() <= 10:\n",
    "        sns.countplot(data=df, x=col)\n",
    "        plt.title(f\"Countplot for {col}\")\n",
    "    \n",
    "    # If the column is numeric with many unique values\n",
    "    else:\n",
    "        sns.histplot(data=df, x=col, bins=30, kde=False)\n",
    "        plt.title(f\"Histogram for {col}\")\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Some of the features could be banded e.g. \n",
    "# BMI could be banded into 1: Underweight, 2: Normal weight, 3: Overweight, 4: Obese \n",
    "# \n",
    "\n",
    "# 1. BMI_Category\n",
    "# 1     31273  \n",
    "# 2    68953 \n",
    "# 3    93749\n",
    "# 4    87851\n",
    "\n",
    "# Define the conditions for BMI categories\n",
    "conditions = [\n",
    "    df[\"BMI\"] <= 18.5,  # Underweight\n",
    "    (df[\"BMI\"] > 18.5) & (df[\"BMI\"] <= 24.8),  # Normal Weight\n",
    "    (df[\"BMI\"] >= 25) & (df[\"BMI\"] <= 29.9),  # Overweight\n",
    "    df[\"BMI\"] >= 30  # Obese\n",
    "]\n",
    "\n",
    "values = [\"Underweight\", \"Normal Weight\", \"Overweight\", \"Obese\"]\n",
    "\n",
    "# Apply np.select to categorize BMI\n",
    "df[\"BMI_Category\"] = np.select(conditions, values, default=\"Unknown\")\n",
    "\n",
    "# Display the value counts of the BMI categories\n",
    "print(df[\"BMI_Category\"].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "## Correlations: Need to specigy Correlations as Spearman as distribution are skewed/not normally distributed \n",
    "# 1. Correlation. Firstly do a full correlation of all features vs all features\n",
    "df_numeric1 = df.select_dtypes(include=[np.number])\n",
    "corr1 = df_numeric1.corr(method=\"spearman\")\n",
    "print(corr1)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "sns.heatmap(\n",
    "    corr1,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.8}\n",
    ")\n",
    "\n",
    "\n",
    "plt.title(\"Correlation Matrix\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Initital dataset saved to CSV format for review and analysis\n",
    "df.to_csv(\"diabetes_cleaned.csv\", index=False)\n",
    "\n",
    "\n",
    "# 2. Correlation. Next do a corrrelation where the target is Diabetes_012\n",
    "df_numeric2 = df.select_dtypes(include=[np.number])\n",
    "corr2 = df_numeric2.corr(method=\"spearman\")[\"Diabetes_012\"].sort_values(ascending=False)\n",
    "print(corr2)\n",
    "\n",
    "# convert to datafrmae for heatmap!\n",
    "corr_df=corr2.to_frame()\n",
    "plt.figure(figsize=(12, 9))\n",
    "sns.heatmap(\n",
    "    corr_df,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.8}\n",
    ")\n",
    "\n",
    "plt.title(\"Correlation Matrix  against Diabetes_012\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation summary: There are not that many strong correlations with Diabetes_012. GenHlth is the best one:\n",
    "# Diabetes_012            1.000000\n",
    "# GenHlth                 0.297138 - Worse general health, higher\n",
    "# HighBP                  0.271668\n",
    "# BMI                     0.235887\n",
    "# DiffWalk                0.223567\n",
    "# HighChol                0.210668\n",
    "# Age                     0.186357\n",
    "# HeartDiseaseorAttack    0.178564\n",
    "# PhysHlth                0.161718\n",
    "# Stroke                  0.105887\n",
    "# CholCheck               0.068018\n",
    "# Smoker                  0.063040\n",
    "# MentHlth                0.044921\n",
    "# NoDocbcCost             0.037379\n",
    "# Sex                     0.030143\n",
    "# AnyHealthcare           0.014530\n",
    "# Fruits                 -0.042268\n",
    "# HvyAlcoholConsump      -0.057244\n",
    "# Veggies                -0.059353\n",
    "# PhysActivity           -0.121988\n",
    "# Education              -0.126862\n",
    "# Income                 -0.172611\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab2f44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Kruskal-Wallis (separate cell) --- Generated by the AI Assistant\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# Map BMI_Category to an ordinal code (if not already present)\n",
    "bmi_order = ['Underweight', 'Normal Weight', 'Overweight', 'Obese']\n",
    "bmi_map = {k: i+1 for i, k in enumerate(bmi_order)}\n",
    "if 'BMI_Category' in df.columns:\n",
    "    df['BMI_Category_Code'] = df['BMI_Category'].map(bmi_map)\n",
    "else:\n",
    "    # fallback: create BMI_Category then map\n",
    "    conditions = [\n",
    "        df['BMI'] <= 18.5,\n",
    "        (df['BMI'] > 18.5) & (df['BMI'] <= 24.8),\n",
    "        (df['BMI'] >= 25) & (df['BMI'] <= 29.9),\n",
    "        df['BMI'] >= 30,\n",
    "    ]\n",
    "    values = ['Underweight', 'Normal Weight', 'Overweight', 'Obese']\n",
    "    df['BMI_Category'] = np.select(conditions, values, default=np.nan)\n",
    "    df['BMI_Category_Code'] = df['BMI_Category'].map(bmi_map)\n",
    "\n",
    "vars_to_test = ['GenHlth', 'BMI', 'BMI_Category_Code']\n",
    "alpha = 0.05\n",
    "labels = sorted(df['Diabetes_012'].dropna().unique())\n",
    "\n",
    "for var in vars_to_test:\n",
    "    groups = [df.loc[df['Diabetes_012'] == g, var].dropna() for g in labels]\n",
    "    non_empty = [grp for grp in groups if len(grp) > 0]\n",
    "    if len(non_empty) < 2:\n",
    "        print(f\"Not enough non-empty groups for {var} - skipping\")\n",
    "        continue\n",
    "    stat, p = kruskal(*non_empty)\n",
    "    medians = {int(lbl): df.loc[df['Diabetes_012']==lbl, var].median() for lbl in labels}\n",
    "    sig = 'reject H0' if p < alpha else 'fail to reject H0'\n",
    "    print(f\"{var}: H={stat:.4f}, p={p:.4e} -> {sig}; medians={medians}\")\n",
    "\n",
    "# Visualise with boxplots\n",
    "for var in vars_to_test:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.boxplot(x='Diabetes_012', y=var, data=df)\n",
    "    plt.title(f\"Boxplot of {var} by Diabetes_012\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Results Summary: \n",
    "# GenHlth: People without diabetes report a median general health of 2 (“Very Good”), whilst people with prediabetes and diabetes \n",
    "# report a median of 3 (“Good”).\n",
    "# Findings: General health declines across diabetes groups. Individuals without diabetes typically report “Very Good” health, whereas \n",
    "# those with prediabetes or diabetes report “Good” health. The difference is statistically significant (p < 0.001).\n",
    "\n",
    "# BMI: People without diabetes report a lower BMI of median 27.0 (range=Overweight), whilst people with prediabetes and diabetes report\n",
    "# a median of 30.0 and 31.0 respectively (Range=Obese).\n",
    "# Findings: BMI increases steadily across diabetes groups. Individuals without diabetes typically fall in the Overwight range, whereas \n",
    "# those with prediabetes or diabetes fall in the Obese range. The difference is statistically significant (p < 0.001) reinforcing the \n",
    "# strong assocaition between higher BMIand diabetes severity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi Sqaure for all of the binary variables. What matters is the Cramers_V score.\n",
    "# Results Summary: \n",
    "# Strongest predictors\n",
    "# HighBP (V=0.272): Moderate, clincially meaningful\n",
    "# DiffWalk (V=0.224): Moderate, clincially meaningful\n",
    "# HighChol (V=0.211): Moderate, clincially meaningful\n",
    "\n",
    "# Weaker but still relevant predictors\n",
    "# HeartDiseaseAttack(V=0.180): Weak but still clinically meaningful\n",
    "# PhysActivity (V=0.122): Weak but still clinically meaningful\n",
    "# Stroke (V=0.107): Weak but still clinically meaningful\n",
    "\n",
    "# Findings to date: \n",
    "# The strongest predicotrs of diabetes are High Blood Presssure, High cholesterol, High BMI/Obesity, poorer general health. mobility ddifficulty and older age.\n",
    "\n",
    "# Moderator predictors are heart disease, physical inactivity and stroke\n",
    "\n",
    "# Weak predictors are: smoking, diet (fruit/vegetables), alcohol, sex and education  \n",
    "\n",
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44186c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square tests for specified binary variables vs Diabetes_012 — combined summary table\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "binary_vars = [\n",
    "    'HighBP',\n",
    "    'HighChol',\n",
    "    'Stroke',\n",
    "    'HeartDiseaseorAttack',\n",
    "    'PhysActivity',\n",
    "    'Smoker',\n",
    "    'Fruits',\n",
    "    'Veggies',\n",
    "    'HvyAlcoholConsump',\n",
    "    'Sex',\n",
    "    'DiffWalk',\n",
    "    'NoDocbcCost'\n",
    " ]\n",
    "labels = sorted(df['Diabetes_012'].dropna().unique())\n",
    "\n",
    "def cramers_v(confusion_matrix):\n",
    "    chi2, p, dof, expected = chi2_contingency(confusion_matrix)\n",
    "    n = confusion_matrix.values.sum()\n",
    "    r, k = confusion_matrix.shape\n",
    "    if n == 0 or min(r-1, k-1) == 0:\n",
    "        return np.nan\n",
    "    return np.sqrt(chi2 / (n * min(r-1, k-1)))\n",
    "\n",
    "results = []\n",
    "print('Computing chi-square and Cramer\\'s V for binary variables vs Diabetes_012...\\n')\n",
    "for var in binary_vars:\n",
    "    if var not in df.columns:\n",
    "        print(f\"{var}: NOT IN DATA -- skipping\\n\")\n",
    "        continue\n",
    "    ct = pd.crosstab(df[var], df['Diabetes_012'])\n",
    "    if ct.size == 0:\n",
    "        print(f\"{var}: empty crosstab -- skipping\\n\")\n",
    "        continue\n",
    "    try:\n",
    "        chi2, p, dof, expected = chi2_contingency(ct)\n",
    "        cv = cramers_v(ct)\n",
    "        # counts of 'positive' (value==1) per Diabetes_012 group when applicable\n",
    "        row = {'variable': var, 'chi2': chi2, 'p': p, 'dof': dof, 'cramers_v': cv}\n",
    "        is_binary_one = df[var].isin([1]).any()\n",
    "        for lbl in labels:\n",
    "            col_name = f'pos_count_{int(lbl)}'\n",
    "            if is_binary_one:\n",
    "                cnt = int(df.loc[(df[var] == 1) & (df['Diabetes_012'] == lbl)].shape[0])\n",
    "            else:\n",
    "                cnt = np.nan\n",
    "            row[col_name] = cnt\n",
    "        results.append(row)\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing {var}: {e}\\n\")\n",
    "\n",
    "# Build summary dataframe\n",
    "if results:\n",
    "    res_df = pd.DataFrame(results)\n",
    "    # ensure pos_count columns appear in order 0,1,2 if present\n",
    "    pos_cols = [c for c in res_df.columns if c.startswith('pos_count_')]\n",
    "    ordered_cols = ['variable', 'chi2', 'p', 'dof', 'cramers_v'] + sorted(pos_cols)\n",
    "    res_df = res_df[ordered_cols]\n",
    "    res_df = res_df.sort_values('cramers_v', ascending=False).reset_index(drop=True)\n",
    "    print('Summary table (sorted by Cramer\\'s V):')\n",
    "    display(res_df)\n",
    "else:\n",
    "    print('No results to display')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15479f5",
   "metadata": {},
   "source": [
    "# Time for Modelling: Logistic Regression First - using AI Agent and modified by the data analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc6d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression using AI Agent and some minor tweaks!\n",
    "# Findings Summary: \n",
    "# Accuracy: 0.8471\n",
    "# Classification report:\n",
    "# Precision = Of all the cases the model said werre diabestes, how many were truly diabetes (i.e. few false positives)\n",
    "# recall = Of all the people who actually have diabetes, how many did the model correctly identify? (i.e. few false negatives)\n",
    "# f1_score: = How well does the model perform when we care about both catching true cases and avoiding false alarms? \n",
    "# Support = How many real examples of this class were in the data?\n",
    "# Class 0: no diabetes\n",
    "# Class 1: prediabetes\n",
    "# Class 2: diabetes\n",
    "\n",
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#           0     0.8636    0.9748    0.9158     42741\n",
    "#           1     0.0000    0.0000    0.0000       926\n",
    "#           2     0.5285    0.1862    0.2753      7069\n",
    "# Logistic regression has a good accuracy level and is good for predicting pre-diabetes but struggles to separte the diabetes classes. So RnadomForest is now needed.\n",
    "# The same variables show up as strong predictors:\n",
    "# HighBP\n",
    "# HIghChol\n",
    "# BMI\n",
    "# GenHlth\n",
    "# DiffWalk\n",
    "# Age\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------\n",
    "# Prepare numeric features & target\n",
    "# -----------------------\n",
    "X = df.select_dtypes(include=[np.number]).copy()\n",
    "if 'Diabetes_012' in X.columns:\n",
    "    X = X.drop(columns=['Diabetes_012'])\n",
    "y = df['Diabetes_012'].astype(int)\n",
    "\n",
    "print(\"Class distribution:\\n\", y.value_counts())\n",
    "\n",
    "# -----------------------\n",
    "# Train/test split\n",
    "# -----------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Scale features\n",
    "# -----------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------\n",
    "# One-vs-Rest Logistic Regression\n",
    "# -----------------------\n",
    "base = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "clf = OneVsRestClassifier(base)   # OVR wrapper\n",
    "clf.fit(X_train_s, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test_s)\n",
    "\n",
    "# -----------------------\n",
    "# Metrics\n",
    "# -----------------------\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {acc:.4f}\")\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=clf.classes_, yticklabels=clf.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - One-vs-Rest Logistic Regression')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# Coefficients per class\n",
    "# -----------------------\n",
    "coef_mat = np.vstack([est.coef_.ravel() for est in clf.estimators_])  # shape (n_classes, n_features)\n",
    "coef_df = pd.DataFrame(coef_mat.T, index=X.columns, columns=[f'class_{c}' for c in clf.classes_])\n",
    "\n",
    "print(\"\\nTop positive/negative coefficients per class:\")\n",
    "for c in coef_df.columns:\n",
    "    top_pos = coef_df[c].sort_values(ascending=False).head(8)\n",
    "    top_neg = coef_df[c].sort_values().head(8)\n",
    "    print(f\"\\n{c} - top positive features:\\n\", top_pos)\n",
    "    print(f\"{c} - top negative features:\\n\", top_neg)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d0b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest using AI Agent with some minor tweaks\n",
    "# Result Sunmarry:\n",
    "# Accuracy: 0.8383396404919584\n",
    "\n",
    "# Classification report:\n",
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#           0     0.8593    0.9688    0.9108     42741\n",
    "#           1     0.0000    0.0000    0.0000       926\n",
    "#           2     0.4682    0.1591    0.2375      7069\n",
    "\n",
    "# # Random Forest has a good accuracy level and is good for predicting peple without diabetes but like logistic regression struggles \n",
    "# to separate the diabetes classes. \n",
    "# TOnce agin he same variables show up as strong predictors:\n",
    "# Top 15 feature importances:\n",
    "# BMI                  0.143816\n",
    "# Age                  0.136396\n",
    "# Income               0.100145\n",
    "# PhysHlth             0.078207\n",
    "# GenHlth              0.071546\n",
    "# Education            0.070318\n",
    "# MentHlth             0.065394\n",
    "# Smoker               0.035637\n",
    "# Fruits               0.035636\n",
    "# Sex                  0.034450\n",
    "# HighBP               0.034131\n",
    "# PhysActivity         0.028288\n",
    "# HighChol             0.028200\n",
    "# Veggies              0.027919\n",
    "# BMI_Category_Code    0.024494\n",
    "# \n",
    "# Overall Summary: Random Forest feature importance identified BMI, age, income, physical health, and general health as the strongest \n",
    "# predictors of diabetes. These findings align closely with the earlier correlation, Chi‑Square, and logistic regression analyses. \n",
    "# Behavioral and lifestyle factors such as smoking, physical activity, and fruit/vegetable intake contributed modestly, \n",
    "# while demographic variables such as sex showed only weak predictive value. \n",
    "# \n",
    "# Summary Overall: Biological and functional health indicators were far more influential than lifestyle factors in predicting diabetes status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest classifier (multiclass) — train / evaluate / importances\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Prepare features and target (same preprocessing as used previously)\n",
    "X = df.select_dtypes(include=[\"number\"]).drop(columns=[\"Diabetes_012\"]).copy()\n",
    "y = df[\"Diabetes_012\"].astype(int)\n",
    "\n",
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# RandomForest — no scaling required, handle imbalance with class_weight\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Feature importances\n",
    "fi = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(\"\\nTop 15 feature importances:\\n\", fi.head(15))\n",
    "\n",
    "# Optional: plot the top importances\n",
    "plt.figure(figsize=(8,6))\n",
    "fi.head(15).sort_values().plot(kind='barh')\n",
    "plt.title('Top 15 RandomForest feature importances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smote + Class_weight using the AI Agent with minor tweaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25393e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fast RandomForest with SMOTE oversampling \n",
    "# Summary: This did not work as expected. Once again the model is good at \n",
    "# predicting no diabetes (code 0) snf diabetes (code 2) but can't distinguish \n",
    "# pre-diabetees (code 1).\n",
    "# Option: create a binary diabetes variable - no diabetes (code 0) and prediabetes + diabetes (code 1 and 2).\n",
    "# Classification report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0     0.9412    0.7055    0.8065     42741\n",
    "#           1     0.0332    0.0097    0.0150       926\n",
    "#           2     0.2962    0.7722    0.4282      7069\n",
    "\n",
    "#    accuracy                         0.7021     50736\n",
    "#   macro avg     0.4235    0.4958    0.4166     50736\n",
    "# weighted avg     0.8348    0.7021    0.7393     50736\n",
    "\n",
    "\n",
    "# Confusion matrix:\n",
    "# [[30153   222 12366]\n",
    "# [  314     9   603]\n",
    "# [ 1570    40  5459]]\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "\n",
    "# Ensure imbalanced-learn (SMOTE) is available\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"imbalanced-learn\"])\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# Configuration\n",
    "# ------------------\n",
    "RANDOM_STATE = 42\n",
    "DATA_PATH = \"diabetes.csv\"\n",
    "MAX_TRAIN_ROWS = 150_000\n",
    "TARGET_PER_CLASS = 30_000  # cap for minority classes\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# Load data\n",
    "# ------------------\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"{DATA_PATH} not found in {os.getcwd()}\")\n",
    "\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "if \"Diabetes_012\" not in df.columns:\n",
    "    raise ValueError(\"Target column 'Diabetes_012' not present\")\n",
    "\n",
    "X = df.select_dtypes(include=\"number\").drop(columns=[\"Diabetes_012\"])\n",
    "y = df[\"Diabetes_012\"].astype(int)\n",
    "\n",
    "print(\"Class distribution (original):\", Counter(y))\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# Train / test split\n",
    "# ------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "print(\"Class distribution (train before SMOTE):\", Counter(y_train))\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# SMOTE (minority-only, capped)\n",
    "# ------------------\n",
    "train_counts = Counter(y_train)\n",
    "major_label, major_count = train_counts.most_common(1)[0]\n",
    "\n",
    "sampling_strategy = {\n",
    "    lbl: min(TARGET_PER_CLASS, major_count)\n",
    "    for lbl, cnt in train_counts.items()\n",
    "    if lbl != major_label\n",
    "}\n",
    "\n",
    "print(\"SMOTE sampling_strategy:\", sampling_strategy)\n",
    "\n",
    "smote = SMOTE(\n",
    "    sampling_strategy=sampling_strategy,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution (train after SMOTE):\", Counter(y_res))\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# Optional downsampling for speed\n",
    "# ------------------\n",
    "if len(y_res) > MAX_TRAIN_ROWS:\n",
    "    print(f\"Downsampling to {MAX_TRAIN_ROWS} rows for fast training...\")\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    idx = rng.choice(len(y_res), size=MAX_TRAIN_ROWS, replace=False)\n",
    "    X_res = X_res.iloc[idx]\n",
    "    y_res = y_res.iloc[idx]\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# RandomForest (SMOTE only, no class_weight)\n",
    "# ------------------\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=80,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=50,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "print(\"Training RandomForest...\")\n",
    "rf.fit(X_res, y_res)\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# Evaluation\n",
    "# ------------------\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Balanced accuracy: {balanced_accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "# ------------------\n",
    "# Feature importances\n",
    "# ------------------\n",
    "fi = (\n",
    "    pd.Series(rf.feature_importances_, index=X.columns)\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "fi.to_csv(\"rf_smote_feature_importances.csv\", header=[\"importance\"])\n",
    "print(\"Saved feature importances to rf_smote_feature_importances.csv\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "fi.head(15).sort_values().plot(kind=\"barh\")\n",
    "plt.title(\"Top 15 RandomForest feature importances (SMOTE)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"rf_smote_feature_importances.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved feature importances plot to rf_smote_feature_importances.png\")\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun Random Forest with binary classification for Diabetes_012\n",
    "# Code generated via ChatGpt and modified by analyst\n",
    "\n",
    "\n",
    "# Random Forest classifier (binary) — train / evaluate / importances\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Prepare features & target\n",
    "# -----------------------\n",
    "X = df.select_dtypes(include=[\"number\"]).drop(columns=[\"Diabetes_012\"]).copy()\n",
    "\n",
    "# Binary target:\n",
    "# 0 = No diabetes\n",
    "# 1 = Prediabetes or Diabetes\n",
    "y = (df[\"Diabetes_012\"] > 0).astype(int)\n",
    "\n",
    "print(\"Binary class distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# -----------------------\n",
    "# Train / test split\n",
    "# -----------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# RandomForest (binary)\n",
    "# -----------------------\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------\n",
    "# Evaluation\n",
    "# -----------------------\n",
    "y_pred = rf.predict(X_test)\n",
    "y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# -----------------------\n",
    "# Feature importances\n",
    "# -----------------------\n",
    "fi = (\n",
    "    pd.Series(rf.feature_importances_, index=X.columns)\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 15 feature importances:\")\n",
    "print(fi.head(15))\n",
    "\n",
    "# Optional plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "fi.head(15).sort_values().plot(kind=\"barh\")\n",
    "plt.title(\"Top 15 RandomForest feature importances (Binary outcome)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
